{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Training of GNN for Link Prediction on Large Graphs \n",
    "\n",
    "본 튜토리얼은 KDD20 자료를 참고하여 작성했습니다. 어떻게 GraphSAGE를 학습하는지에 대한 내용을 다룹니다. \n",
    "\n",
    "## Link Prediction Overview \n",
    "\n",
    "Link Prediction을 수행할 때 우리는 Link을 $s_{uv} = \\phi ( h^{(l)}_u, h^{(l)}_v) $ 로 표현합니다. 이때 $s_{uv}$는 두 노드가 연결되어 있을 확률을 의미합니다. \n",
    "\n",
    "이때 negative sampling을 사용해 실제 연결된 값과 연결되지 않은 값을 비교해서 값을 산출하며 손실함수는 아래와 같이 정의합니다.\n",
    "\n",
    "$$ \\mathcal{L} = -\\log \\sigma (s_{uv}) - Q \\mathbb{E}_{v^- \\in P^- (v)} [ \\sigma ( - s_{uv^-})] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import dgl \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import numpy as np \n",
    "import utils_KDD\n",
    "import pickle\n",
    "\n",
    "with open('../data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "graph, node_features, node_labels, train_nids, valid_nids, test_nids = data \n",
    "graph.create_formats_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGL 패키지는 edge classification, link prediction task를 수행하기 위한 `EdgeDataLoader`를 제공합니다.\n",
    "\n",
    "edge prediction을 수행하기 위해서는 먼저 negative sampling을 사용하여야 하기 때문에 해당 함수를 먼저 정의합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSampler(object):\n",
    "    def __init__(self, g, k):\n",
    "        self.k = k \n",
    "        self.weights = g.in_degrees().float() ** 0.75 \n",
    "    \n",
    "    def __call__(self, g, eids):\n",
    "        src, _ = g.find_edges(eids)\n",
    "        src = src.pepeat_interleave(self.k)\n",
    "        dst =self.weights.multinomial(len(src), replacement = True)\n",
    "        return src, dst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([4, 4, 4])\n",
    "k = 5 \n",
    "train_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    graph, torch.arange(graph.number_of_edges()), sampler, \n",
    "    negative_sampler = NegativeSampler(graph, k),\n",
    "    batch_size = 1024, \n",
    "    shuffle = True, \n",
    "    drop_last = False, \n",
    "    num_workers = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_minibatch = next(iter(train_dataloader))\n",
    "print(example_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes, pos_graph, neg_graph, bipartites = example_minibatch \n",
    "print('Number of input nodes:', len(input_nodes))\n",
    "print('Positive graph # nodes:', pos_graph.number_of_nodes(), '# edges:', pos_graph.number_of_edges())\n",
    "print('Negative graph # nodes:', neg_graph.number_of_nodes(), '# edges:', neg_graph.number_of_edges())\n",
    "print(bipartites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model for Node Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import dgl.nn as dglnn\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_layers):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.in_feats = in_feats \n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats, n_hidden, 'mean'))\n",
    "        for i in range(1, self.n_layers):\n",
    "            self.layers.append(n_hidden, n_hidden, 'mean')\n",
    "        \n",
    "    def forward(self, bipartites, x):\n",
    "        for l, (layer, bipartite) in enumerate(zip(self.layers, bipartites)):\n",
    "            x = layer(bipartites, x)\n",
    "            if l != self.n_layers - 1:\n",
    "                x = F.relu(x)\n",
    "            \n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Node Representation from GNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, graph, in_feats, batch_size):\n",
    "    nodes = torch.arange(graph.number_of_nodes())\n",
    "\n",
    "    sampler = dgl.dataloading.MultiLayerNeighborSampler([None])\n",
    "    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "        graph, nodes, sampler, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = False, \n",
    "        drop_last = False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for l, layer in enumerate(model.layers):\n",
    "            output_features = torch.zeros(graph.number_of_nodes(), model.n_hidden)\n",
    "            for input_nodes, output_nodes, bipartites in tqdm.tqdm(dataloader):\n",
    "                bipartite = bipartites[0].to('cuda')\n",
    "                x = in_feats[input_nodes].to('cuda')\n",
    "\n",
    "                x = layer(bipartite, x)\n",
    "                if l != model.n_layers - 1:\n",
    "                    x = F.relu(x)\n",
    "                \n",
    "                output_features[output_nodes] = x.cpu()\n",
    "            in_feats = output_features \n",
    "    return output_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScorePredictor(nn.Module):\n",
    "    def forward(self, subgraph, x):\n",
    "        with subgraph.local_scope():\n",
    "            subgraph.ndata['x'] = x \n",
    "            subgraph.apply_edges(dgl.function.u_dot_v('x', 'x', 'score'))\n",
    "            return subgraph.edata['score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance of the Learned Embedding\n",
    "\n",
    "GraphGAGE 논문에서는 LSTM, Linear 등 다양한 classifier를 사용해서 classification을 수행하지만, 본 튜토리얼에서는 Linear Classifier를 사용해서 분류를 진행하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "def evaluate(emb, label, train_nids, valid_nids, test_nids):\n",
    "    classifier = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial', verbose=1, max_iter =1000)\n",
    "    classifier.fit(emb[train_nids], label[train_nids])\n",
    "    valid_pred = classifier.predict(emb[valid_nids])\n",
    "    test_pred = classifier.predict(emb[test_nids])\n",
    "    valid_acc = metrics.accuracy_score(label[valid_nids], valid_pred)\n",
    "    test_acc = metrics.accuracy_score(label[test_nids], test_pred)\n",
    "    return valid_acc, test_acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(node_features.shape[1], 128, 3).to('cuda')\n",
    "predictor = ScorePredictor().to('cuda')\n",
    "optimizer = optim.Adam(list(model.parameters()) + list(predictor.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0 \n",
    "best_model_path = 'model.pt'\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step, (input_nodes, pos_graph, neg_graph, bipartites) in enumerate(tq):\n",
    "            bipartites = [b.to('cuda') for b in bipartites]\n",
    "            pos_graph = pos_graph.to('cuda')\n",
    "            neg_graph = neg_graph.to('cuda')\n",
    "            inputs = node_features[input_nodes].to('cuda')\n",
    "            outputs = model(bipartites, inputs)\n",
    "            pos_score = predictor(pos_graph, outputs)\n",
    "            neg_score = predictor(neg_graph, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
