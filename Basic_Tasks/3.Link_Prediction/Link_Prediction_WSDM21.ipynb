{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Prediction using Graph Neural Networks\n",
    "\n",
    "Graph에서는 node classification, graph classification, link prediction 등의 다양한 task가 존재합니다. 이번 튜토리얼에서는 그 중 Link Preidiction에 대해서 다룹니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl \n",
    "import dgl.function as fn \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import itertools \n",
    "import numpy as np \n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Link Prediction with GNN \n",
    "\n",
    "social recoomendation, item recommendation, knowledge graph 등 다양한 application 연구가 존재합니다. 이때, 각 node들이 연결되어 있는지 아닌지를 예측하는 것이 바로 Link Prediction 입니다. \n",
    "\n",
    "본 튜토리얼에서는 citation network data를 사용해서 두 논문 간의 인용 관계를 예측하고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading graph and features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl.data \n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare traning and testing sets \n",
    "\n",
    "본 튜토리얼에서는 edge의 10%만 추출해서 test set으로 사용하고 나머지는 training set으로 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_size = int(len(eids)*0.1)\n",
    "\n",
    "train_size = g.number_of_edges() - test_size \n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "\n",
    "# negative edge\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy()))) # 인접행렬을 생성합니다. coo_marix(data, (row, col)) row와 col에 동시에 출현하는 index는 1로 mapping하는 것입니다.\n",
    "adj_neg = 1 - adj.todense() # negative edge를 찾는 것이기 때문에 1을 빼서 adj_neg를 생성합니다.\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges()//2)\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `dgl.remove_edges`로 test의 edge를 삭제하고 이를 예측하는 형태로 변환한 후 학습을 진행합니다.\n",
    "train_g = dgl.remove_edges(g, eids[:test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a GraphSAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv \n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "\n",
    "        self.in_feats = in_feats \n",
    "        self.h_feats = h_feats \n",
    "\n",
    "        self.conv1 = SAGEConv(self.in_feats, self.h_feats, aggregator_type = 'mean')\n",
    "        self.conv2 = SAGEConv(self.h_feats, self.h_feats, aggregator_type = 'mean')\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, g, in_feats):\n",
    "        h = self.conv1(g, in_feats)\n",
    "        h = self.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h \n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score')) # `h`: source node, `h` destination node\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats*2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h'], 1])\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "    \n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
    "\n",
    "pred = DotPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def criterion(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def accuracy(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.2586\n",
      "In epoch 10, loss: 0.2549\n",
      "In epoch 15, loss: 0.2514\n",
      "In epoch 20, loss: 0.2477\n",
      "In epoch 25, loss: 0.2441\n",
      "In epoch 30, loss: 0.2405\n",
      "In epoch 35, loss: 0.2369\n",
      "In epoch 40, loss: 0.2333\n",
      "In epoch 45, loss: 0.2296\n",
      "In epoch 50, loss: 0.2260\n",
      "In epoch 55, loss: 0.2223\n",
      "In epoch 60, loss: 0.2186\n",
      "In epoch 65, loss: 0.2149\n",
      "In epoch 70, loss: 0.2111\n",
      "In epoch 75, loss: 0.2073\n",
      "In epoch 80, loss: 0.2035\n",
      "In epoch 85, loss: 0.1997\n",
      "In epoch 90, loss: 0.1959\n",
      "In epoch 95, loss: 0.1920\n",
      "In epoch 100, loss: 0.1881\n",
      "AUC 0.8853808315177107\n"
     ]
    }
   ],
   "source": [
    "all_logits = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "for epoch in range(100):\n",
    "    h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = criterion(pos_score, neg_score)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 5 == 0 :\n",
    "        print(f'In epoch {epoch+1}, loss: {loss:.4f}')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', accuracy(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
