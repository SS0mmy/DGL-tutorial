{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Classification with DGL \n",
    "\n",
    "본 튜토리얼은 WSDM21 Conference를 참고해서 작성했습니다. `DGL`을 사용해서 Node Classification을 하는 방법에 대해서 다룹니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Number of Categories: 7\n"
     ]
    }
   ],
   "source": [
    "# CoraDataset을 이용해서 semi-supervised node classification을 수행합니다. \n",
    "# https://arxiv.org/abs/1609.02907 : 해당 논문은 GCN을 처음 제안한 논문입니다. GCN에 관련된 내용은 https://ok-lab.tistory.com/205?category=940094 여기를 참고하시면 됩니다.\n",
    "import dgl.data \n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "print('Number of Categories:', dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n"
     ]
    }
   ],
   "source": [
    "g = dataset[0]\n",
    "\n",
    "print('Number of nodes:', g.num_nodes())\n",
    "print('Number of edges:', g.num_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DGLGraph`에서 제공하는 데이터셋에는 `ndata`와 `edata`로 구성되어 있으며, 추가적으로 그래프는 아래와 같은 `node features`들로 구성되어 있습니다.\n",
    "\n",
    "- `train_mask`: node가 학습 데이터셋인지 아닌지 boolean 값으로 되어 있습니다. \n",
    "- `val_mask`: node가 검증 데이터셋인지 아닌지 boolean 값으로 되어 있습니다.\n",
    "- `test_mask`: node가 테스트 데이터셋인지 아닌지 boolean 값으로 되어 있습니다.\n",
    "- `label`: node 카테고리 정답값입니다. \n",
    "- `feat`: node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature names: dict_keys(['feat', 'label', 'test_mask', 'train_mask', 'val_mask'])\n",
      "Edge feature names: dict_keys(['__orig__'])\n"
     ]
    }
   ],
   "source": [
    "print('Node feature names:', g.ndata.keys())\n",
    "print('Edge feature names:', g.edata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training nodes: 140\n",
      "Number of validating nodes: 500\n",
      "Number of testing nodes: 1000\n",
      "Number of classes: 7\n",
      "Node feature shape: torch.Size([2708, 1433])\n"
     ]
    }
   ],
   "source": [
    "print('Number of training nodes:', g.ndata['train_mask'].int().sum().item())\n",
    "print('Number of validating nodes:', g.ndata['val_mask'].int().sum().item())\n",
    "print('Number of testing nodes:', g.ndata['test_mask'].int().sum().item())\n",
    "\n",
    "print('Number of classes:', (g.ndata['label'].max()+1).item())\n",
    "print('Node feature shape:', g.ndata['feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv \n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, n_hidden, 'both')\n",
    "        self.conv2 = GraphConv(n_hidden, n_classes, 'both')\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        output = self.conv1(g, in_feat)\n",
    "        output = self.relu(output)\n",
    "        output = self.conv2(g, output)\n",
    "        return output \n",
    "\n",
    "models = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch [50/1000]\t loss: 1.869\t train_acc: 88.57%\t val_acc: 65.60%\t test_acc: 69.50%\n",
      "best val acc: 65.60%\t best test acc: 68.90%\n",
      "\n",
      "In epoch [100/1000]\t loss: 1.744\t train_acc: 92.86%\t val_acc: 68.00%\t test_acc: 71.00%\n",
      "best val acc: 68.60%\t best test acc: 71.00%\n",
      "\n",
      "In epoch [150/1000]\t loss: 1.577\t train_acc: 96.43%\t val_acc: 70.40%\t test_acc: 73.40%\n",
      "best val acc: 70.40%\t best test acc: 73.40%\n",
      "\n",
      "In epoch [200/1000]\t loss: 1.381\t train_acc: 97.14%\t val_acc: 73.00%\t test_acc: 73.90%\n",
      "best val acc: 73.00%\t best test acc: 73.70%\n",
      "\n",
      "In epoch [250/1000]\t loss: 1.175\t train_acc: 97.86%\t val_acc: 74.40%\t test_acc: 75.10%\n",
      "best val acc: 74.40%\t best test acc: 74.90%\n",
      "\n",
      "In epoch [300/1000]\t loss: 0.978\t train_acc: 97.86%\t val_acc: 75.40%\t test_acc: 75.30%\n",
      "best val acc: 75.40%\t best test acc: 75.20%\n",
      "\n",
      "In epoch [350/1000]\t loss: 0.803\t train_acc: 100.00%\t val_acc: 77.00%\t test_acc: 75.70%\n",
      "best val acc: 77.00%\t best test acc: 75.80%\n",
      "\n",
      "In epoch [400/1000]\t loss: 0.655\t train_acc: 100.00%\t val_acc: 76.80%\t test_acc: 76.00%\n",
      "best val acc: 77.40%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [450/1000]\t loss: 0.534\t train_acc: 100.00%\t val_acc: 77.00%\t test_acc: 75.70%\n",
      "best val acc: 77.40%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [500/1000]\t loss: 0.437\t train_acc: 100.00%\t val_acc: 77.40%\t test_acc: 76.10%\n",
      "best val acc: 77.40%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [550/1000]\t loss: 0.360\t train_acc: 100.00%\t val_acc: 77.40%\t test_acc: 76.30%\n",
      "best val acc: 77.80%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [600/1000]\t loss: 0.299\t train_acc: 100.00%\t val_acc: 77.00%\t test_acc: 76.40%\n",
      "best val acc: 77.80%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [650/1000]\t loss: 0.250\t train_acc: 100.00%\t val_acc: 77.20%\t test_acc: 76.30%\n",
      "best val acc: 77.80%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [700/1000]\t loss: 0.211\t train_acc: 100.00%\t val_acc: 77.80%\t test_acc: 76.10%\n",
      "best val acc: 77.80%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [750/1000]\t loss: 0.179\t train_acc: 100.00%\t val_acc: 78.00%\t test_acc: 76.00%\n",
      "best val acc: 78.20%\t best test acc: 75.90%\n",
      "\n",
      "In epoch [800/1000]\t loss: 0.154\t train_acc: 100.00%\t val_acc: 78.20%\t test_acc: 75.90%\n",
      "best val acc: 78.20%\t best test acc: 75.90%\n",
      "\n",
      "In epoch [850/1000]\t loss: 0.133\t train_acc: 100.00%\t val_acc: 78.20%\t test_acc: 75.90%\n",
      "best val acc: 78.40%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [900/1000]\t loss: 0.115\t train_acc: 100.00%\t val_acc: 78.20%\t test_acc: 76.00%\n",
      "best val acc: 78.40%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [950/1000]\t loss: 0.101\t train_acc: 100.00%\t val_acc: 78.20%\t test_acc: 75.80%\n",
      "best val acc: 78.40%\t best test acc: 76.00%\n",
      "\n",
      "In epoch [1000/1000]\t loss: 0.088\t train_acc: 100.00%\t val_acc: 78.00%\t test_acc: 75.80%\n",
      "best val acc: 78.40%\t best test acc: 76.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def criterion(pred_y, true_y, mask):\n",
    "    pred_y = pred_y[mask]\n",
    "    true_y = true_y[mask]\n",
    "    return F.cross_entropy(pred_y, true_y)\n",
    "\n",
    "def accuracy(pred_y, true_y, mask):\n",
    "    pred_y = pred_y[mask]\n",
    "    true_y = true_y[mask]\n",
    "    return (pred_y == true_y).float().mean()\n",
    "\n",
    "def trainer(g, model, n_epoch, device):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    best_val_acc = 0 \n",
    "    best_test_acc = 0 \n",
    "    g = g.to(device)\n",
    "    features = g.ndata['feat'].to(device)\n",
    "    labels = g.ndata['label'].to(device)\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "\n",
    "    for epoch in range(1, n_epoch+1):\n",
    "        pred_y = model(g, features).to(device)\n",
    "        loss = criterion(pred_y, labels, train_mask)\n",
    "        pred_y = pred_y.argmax(1)\n",
    "        train_acc = accuracy(pred_y, labels, train_mask)\n",
    "        val_acc = accuracy(pred_y, labels, val_mask)\n",
    "        test_acc = accuracy(pred_y, labels, test_mask)\n",
    "\n",
    "        if best_val_acc < val_acc : \n",
    "            best_val_acc = val_acc \n",
    "            best_test_acc = test_acc \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 50 == 0 :\n",
    "            print(f'In epoch [{epoch}/{n_epoch}]\\t loss: {loss:.3f}\\t train_acc: {train_acc*100:.2f}%\\t val_acc: {val_acc*100:.2f}%\\t test_acc: {test_acc*100:.2f}%')\n",
    "            print(f'best val acc: {best_val_acc*100:.2f}%\\t best test acc: {best_test_acc*100:.2f}%\\n')\n",
    "            \n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes).to(device)\n",
    "\n",
    "trainer(g, model, 1000, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
